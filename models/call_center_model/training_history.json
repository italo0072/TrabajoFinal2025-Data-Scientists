{
  "training_time_minutes": 12.664855404694874,
  "training_loss": 0.2241414121840142,
  "global_steps": 6252,
  "logs": [
    {
      "loss": 0.693,
      "grad_norm": 0.6804987788200378,
      "learning_rate": 3.96e-06,
      "epoch": 0.064,
      "step": 100
    },
    {
      "loss": 0.5603,
      "grad_norm": 2.6217598915100098,
      "learning_rate": 7.960000000000002e-06,
      "epoch": 0.128,
      "step": 200
    },
    {
      "loss": 0.403,
      "grad_norm": 8.107418060302734,
      "learning_rate": 1.196e-05,
      "epoch": 0.192,
      "step": 300
    },
    {
      "loss": 0.3736,
      "grad_norm": 7.758127689361572,
      "learning_rate": 1.5920000000000003e-05,
      "epoch": 0.256,
      "step": 400
    },
    {
      "loss": 0.3438,
      "grad_norm": 6.565966606140137,
      "learning_rate": 1.9920000000000002e-05,
      "epoch": 0.32,
      "step": 500
    },
    {
      "loss": 0.3696,
      "grad_norm": 3.4033639430999756,
      "learning_rate": 1.9870456047587577e-05,
      "epoch": 0.384,
      "step": 600
    },
    {
      "loss": 0.3392,
      "grad_norm": 6.722216606140137,
      "learning_rate": 1.9738268341044284e-05,
      "epoch": 0.448,
      "step": 700
    },
    {
      "loss": 0.349,
      "grad_norm": 4.323284149169922,
      "learning_rate": 1.9606080634500994e-05,
      "epoch": 0.512,
      "step": 800
    },
    {
      "loss": 0.3375,
      "grad_norm": 3.3197803497314453,
      "learning_rate": 1.94738929279577e-05,
      "epoch": 0.576,
      "step": 900
    },
    {
      "loss": 0.343,
      "grad_norm": 7.269623279571533,
      "learning_rate": 1.934170522141441e-05,
      "epoch": 0.64,
      "step": 1000
    },
    {
      "loss": 0.323,
      "grad_norm": 4.970836639404297,
      "learning_rate": 1.9209517514871118e-05,
      "epoch": 0.704,
      "step": 1100
    },
    {
      "loss": 0.3325,
      "grad_norm": 4.913078784942627,
      "learning_rate": 1.9077329808327828e-05,
      "epoch": 0.768,
      "step": 1200
    },
    {
      "loss": 0.3099,
      "grad_norm": 3.9138519763946533,
      "learning_rate": 1.8945142101784535e-05,
      "epoch": 0.832,
      "step": 1300
    },
    {
      "loss": 0.3057,
      "grad_norm": 4.588244915008545,
      "learning_rate": 1.8812954395241242e-05,
      "epoch": 0.896,
      "step": 1400
    },
    {
      "loss": 0.3169,
      "grad_norm": 7.1483964920043945,
      "learning_rate": 1.8680766688697952e-05,
      "epoch": 0.96,
      "step": 1500
    },
    {
      "eval_loss": 0.3070060908794403,
      "eval_accuracy": 0.8701,
      "eval_f1": 0.8758244909664468,
      "eval_precision": 0.85498320268757,
      "eval_recall": 0.8977072310405644,
      "eval_runtime": 6.9546,
      "eval_samples_per_second": 1437.906,
      "eval_steps_per_second": 45.006,
      "epoch": 1.0,
      "step": 1563
    },
    {
      "loss": 0.2772,
      "grad_norm": 4.123245716094971,
      "learning_rate": 1.8548578982154662e-05,
      "epoch": 1.02368,
      "step": 1600
    },
    {
      "loss": 0.2311,
      "grad_norm": 6.432834148406982,
      "learning_rate": 1.841639127561137e-05,
      "epoch": 1.08768,
      "step": 1700
    },
    {
      "loss": 0.2566,
      "grad_norm": 2.779557466506958,
      "learning_rate": 1.8284203569068076e-05,
      "epoch": 1.15168,
      "step": 1800
    },
    {
      "loss": 0.2391,
      "grad_norm": 5.980569839477539,
      "learning_rate": 1.8152015862524786e-05,
      "epoch": 1.21568,
      "step": 1900
    },
    {
      "loss": 0.2559,
      "grad_norm": 9.074070930480957,
      "learning_rate": 1.8019828155981496e-05,
      "epoch": 1.27968,
      "step": 2000
    },
    {
      "loss": 0.256,
      "grad_norm": 7.673917770385742,
      "learning_rate": 1.7887640449438203e-05,
      "epoch": 1.34368,
      "step": 2100
    },
    {
      "loss": 0.2531,
      "grad_norm": 3.16230845451355,
      "learning_rate": 1.7755452742894914e-05,
      "epoch": 1.40768,
      "step": 2200
    },
    {
      "loss": 0.252,
      "grad_norm": 6.298011779785156,
      "learning_rate": 1.762326503635162e-05,
      "epoch": 1.47168,
      "step": 2300
    },
    {
      "loss": 0.2506,
      "grad_norm": 3.890042781829834,
      "learning_rate": 1.749107732980833e-05,
      "epoch": 1.5356800000000002,
      "step": 2400
    },
    {
      "loss": 0.2305,
      "grad_norm": 6.636317729949951,
      "learning_rate": 1.736021150033047e-05,
      "epoch": 1.59968,
      "step": 2500
    },
    {
      "loss": 0.2188,
      "grad_norm": 5.768613815307617,
      "learning_rate": 1.722802379378718e-05,
      "epoch": 1.66368,
      "step": 2600
    },
    {
      "loss": 0.2422,
      "grad_norm": 4.799962043762207,
      "learning_rate": 1.7095836087243887e-05,
      "epoch": 1.7276799999999999,
      "step": 2700
    },
    {
      "loss": 0.2386,
      "grad_norm": 6.1185455322265625,
      "learning_rate": 1.6963648380700597e-05,
      "epoch": 1.79168,
      "step": 2800
    },
    {
      "loss": 0.2581,
      "grad_norm": 3.0893399715423584,
      "learning_rate": 1.6831460674157304e-05,
      "epoch": 1.85568,
      "step": 2900
    },
    {
      "loss": 0.2392,
      "grad_norm": 4.301191806793213,
      "learning_rate": 1.6699272967614014e-05,
      "epoch": 1.91968,
      "step": 3000
    },
    {
      "loss": 0.2412,
      "grad_norm": 2.417694568634033,
      "learning_rate": 1.656708526107072e-05,
      "epoch": 1.98368,
      "step": 3100
    },
    {
      "eval_loss": 0.2951051890850067,
      "eval_accuracy": 0.8838,
      "eval_f1": 0.8865012697792538,
      "eval_precision": 0.8837390457643622,
      "eval_recall": 0.8892808152067412,
      "eval_runtime": 6.9402,
      "eval_samples_per_second": 1440.885,
      "eval_steps_per_second": 45.1,
      "epoch": 2.0,
      "step": 3126
    },
    {
      "loss": 0.1818,
      "grad_norm": 4.612814903259277,
      "learning_rate": 1.6434897554527428e-05,
      "epoch": 2.04736,
      "step": 3200
    },
    {
      "loss": 0.15,
      "grad_norm": 6.531674385070801,
      "learning_rate": 1.630270984798414e-05,
      "epoch": 2.11136,
      "step": 3300
    },
    {
      "loss": 0.1775,
      "grad_norm": 4.342546463012695,
      "learning_rate": 1.617052214144085e-05,
      "epoch": 2.17536,
      "step": 3400
    },
    {
      "loss": 0.1638,
      "grad_norm": 7.350275039672852,
      "learning_rate": 1.6039656311962988e-05,
      "epoch": 2.23936,
      "step": 3500
    },
    {
      "loss": 0.1604,
      "grad_norm": 2.4139113426208496,
      "learning_rate": 1.5907468605419698e-05,
      "epoch": 2.30336,
      "step": 3600
    },
    {
      "loss": 0.1688,
      "grad_norm": 5.9612627029418945,
      "learning_rate": 1.5775280898876405e-05,
      "epoch": 2.36736,
      "step": 3700
    },
    {
      "loss": 0.1584,
      "grad_norm": 4.269944667816162,
      "learning_rate": 1.5643093192333115e-05,
      "epoch": 2.43136,
      "step": 3800
    },
    {
      "loss": 0.162,
      "grad_norm": 6.838663101196289,
      "learning_rate": 1.5510905485789822e-05,
      "epoch": 2.49536,
      "step": 3900
    },
    {
      "loss": 0.1657,
      "grad_norm": 7.4146881103515625,
      "learning_rate": 1.537871777924653e-05,
      "epoch": 2.55936,
      "step": 4000
    },
    {
      "loss": 0.1704,
      "grad_norm": 8.947229385375977,
      "learning_rate": 1.5246530072703241e-05,
      "epoch": 2.62336,
      "step": 4100
    },
    {
      "loss": 0.1782,
      "grad_norm": 5.669413089752197,
      "learning_rate": 1.511434236615995e-05,
      "epoch": 2.68736,
      "step": 4200
    },
    {
      "loss": 0.1606,
      "grad_norm": 9.296530723571777,
      "learning_rate": 1.4982154659616656e-05,
      "epoch": 2.75136,
      "step": 4300
    },
    {
      "loss": 0.1651,
      "grad_norm": 9.003263473510742,
      "learning_rate": 1.4849966953073365e-05,
      "epoch": 2.81536,
      "step": 4400
    },
    {
      "loss": 0.181,
      "grad_norm": 6.7468085289001465,
      "learning_rate": 1.4717779246530073e-05,
      "epoch": 2.87936,
      "step": 4500
    },
    {
      "loss": 0.151,
      "grad_norm": 3.779123067855835,
      "learning_rate": 1.4585591539986784e-05,
      "epoch": 2.94336,
      "step": 4600
    },
    {
      "eval_loss": 0.37143251299858093,
      "eval_accuracy": 0.882,
      "eval_f1": 0.8838125246159906,
      "eval_precision": 0.8881852364931724,
      "eval_recall": 0.8794826572604351,
      "eval_runtime": 7.2189,
      "eval_samples_per_second": 1385.262,
      "eval_steps_per_second": 43.359,
      "epoch": 3.0,
      "step": 4689
    },
    {
      "loss": 0.1644,
      "grad_norm": 3.3699328899383545,
      "learning_rate": 1.445340383344349e-05,
      "epoch": 3.00704,
      "step": 4700
    },
    {
      "loss": 0.1006,
      "grad_norm": 10.157773971557617,
      "learning_rate": 1.4321216126900199e-05,
      "epoch": 3.07104,
      "step": 4800
    },
    {
      "loss": 0.0956,
      "grad_norm": 15.631893157958984,
      "learning_rate": 1.4189028420356908e-05,
      "epoch": 3.13504,
      "step": 4900
    },
    {
      "loss": 0.1201,
      "grad_norm": 10.005513191223145,
      "learning_rate": 1.4056840713813618e-05,
      "epoch": 3.19904,
      "step": 5000
    },
    {
      "loss": 0.1088,
      "grad_norm": 7.328388214111328,
      "learning_rate": 1.3924653007270326e-05,
      "epoch": 3.26304,
      "step": 5100
    },
    {
      "loss": 0.1066,
      "grad_norm": 2.5616049766540527,
      "learning_rate": 1.3792465300727033e-05,
      "epoch": 3.32704,
      "step": 5200
    },
    {
      "loss": 0.1109,
      "grad_norm": 23.293771743774414,
      "learning_rate": 1.3660277594183742e-05,
      "epoch": 3.39104,
      "step": 5300
    },
    {
      "loss": 0.1216,
      "grad_norm": 11.918377876281738,
      "learning_rate": 1.352808988764045e-05,
      "epoch": 3.45504,
      "step": 5400
    },
    {
      "loss": 0.1134,
      "grad_norm": 5.175951957702637,
      "learning_rate": 1.339590218109716e-05,
      "epoch": 3.51904,
      "step": 5500
    },
    {
      "loss": 0.1264,
      "grad_norm": 12.135322570800781,
      "learning_rate": 1.32650363516193e-05,
      "epoch": 3.58304,
      "step": 5600
    },
    {
      "loss": 0.1011,
      "grad_norm": 3.3068020343780518,
      "learning_rate": 1.3132848645076009e-05,
      "epoch": 3.64704,
      "step": 5700
    },
    {
      "loss": 0.0994,
      "grad_norm": 15.620439529418945,
      "learning_rate": 1.3001982815598151e-05,
      "epoch": 3.71104,
      "step": 5800
    },
    {
      "loss": 0.1169,
      "grad_norm": 0.8774091601371765,
      "learning_rate": 1.286979510905486e-05,
      "epoch": 3.7750399999999997,
      "step": 5900
    },
    {
      "loss": 0.1207,
      "grad_norm": 8.69338607788086,
      "learning_rate": 1.2737607402511567e-05,
      "epoch": 3.83904,
      "step": 6000
    },
    {
      "loss": 0.109,
      "grad_norm": 0.7632412314414978,
      "learning_rate": 1.2605419695968275e-05,
      "epoch": 3.90304,
      "step": 6100
    },
    {
      "loss": 0.0965,
      "grad_norm": 12.160453796386719,
      "learning_rate": 1.2473231989424985e-05,
      "epoch": 3.96704,
      "step": 6200
    },
    {
      "eval_loss": 0.3918425440788269,
      "eval_accuracy": 0.8753,
      "eval_f1": 0.8805669954985155,
      "eval_precision": 0.8611839640314725,
      "eval_recall": 0.9008426415833823,
      "eval_runtime": 6.9079,
      "eval_samples_per_second": 1447.618,
      "eval_steps_per_second": 45.31,
      "epoch": 4.0,
      "step": 6252
    },
    {
      "train_runtime": 759.7828,
      "train_samples_per_second": 658.083,
      "train_steps_per_second": 20.572,
      "total_flos": 7451291174400000.0,
      "train_loss": 0.2241414121840142,
      "epoch": 4.0,
      "step": 6252
    }
  ],
  "test_results": {
    "accuracy": 0.8838,
    "f1": 0.8865012697792538,
    "precision": 0.8837390457643622,
    "recall": 0.8892808152067412,
    "loss": 0.2951051890850067
  }
}